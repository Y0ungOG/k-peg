{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install -q optax dm-haiku"
      ],
      "metadata": {
        "id": "b5lSRB8Ufuz1",
        "outputId": "6fcc01cc-b1ca-4093-8525-355464569067",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/371.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/371.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m371.0/371.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Due Date: November 6th\n",
        "# Part 1 (80 %)\n",
        "\n",
        "The code below is similar to the Cake Eating problem code we implemented in class. The difference is that the consumption policy function is written as a simple sigle-layer neural network, with tanh activation.\n",
        "\n",
        "We will interpret the size of the cake as being total wealth, and cake consumption as general consumption. The fraction of wealth not consumed today are the *savings* (line 51). The dynamics of wealth are described by line 54. That line is equivalent to assuming that your savings are invested in a risk-free savings account that pays 0 interest, and therefore has a gross return of 1, denoted by *R* (line 53).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NBCYxZPBaiLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import optax\n",
        "import haiku as hk\n",
        "\n",
        "\n",
        "γ = 2.\n",
        "β = 0.95\n",
        "\n",
        "\n",
        "def U(c):\n",
        "    return c**(1 - γ) / (1 - γ)\n",
        "\n",
        "\n",
        "optimizer = optax.adam\n",
        "lr = 1e-3\n",
        "T = 50\n",
        "\n",
        "\n",
        "def nnet(x):\n",
        "  X = jnp.column_stack([x])\n",
        "  X = hk.Linear(32)(X)\n",
        "  X = jnp.tanh(X)\n",
        "  X = hk.Linear(1)(X)\n",
        "  X = jnp.squeeze(X)\n",
        "  return X\n",
        "\n",
        "\n",
        "init, nnet = hk.without_apply_rng(hk.transform(nnet))\n",
        "rng = jax.random.PRNGKey(0)\n",
        "Θ = init(rng, jnp.array(1.))\n",
        "\n",
        "\n",
        "opt_state = optimizer(lr).init(Θ)\n",
        "\n",
        "\n",
        "def L(Θ):\n",
        "\n",
        "  x = 1.\n",
        "  G = 0.\n",
        "\n",
        "  state = x\n",
        "  inputs = jnp.arange(T)\n",
        "\n",
        "  def core(state, inputs):\n",
        "    t = inputs\n",
        "    xt = state\n",
        "\n",
        "    ct = jax.nn.sigmoid(nnet(Θ, xt) - 4.) * xt\n",
        "    ut = U(ct)\n",
        "    savings = xt - ct\n",
        "\n",
        "    R = 1.\n",
        "    x_tp1 = R * savings\n",
        "\n",
        "    discounted_utility = β**t * ut\n",
        "    return x_tp1, discounted_utility\n",
        "\n",
        "  x, discounted_utility = jax.lax.scan(core, state, inputs)\n",
        "  G = discounted_utility.sum()\n",
        "  return -G\n",
        "\n",
        "\n",
        "@jax.jit\n",
        "def evaluation(Θ):\n",
        "  return -L(Θ)\n",
        "\n",
        "\n",
        "@jax.jit\n",
        "def update_gradient_descent(Θ, opt_state):\n",
        "  grad = jax.grad(L)(Θ)\n",
        "  updates, opt_state = optimizer(lr).update(grad, opt_state)\n",
        "  Θ = optax.apply_updates(Θ, updates)\n",
        "  return Θ, opt_state\n",
        "\n",
        "\n",
        "for iteration in range(100000):\n",
        "  Θ, opt_state = update_gradient_descent(Θ, opt_state)\n",
        "\n",
        "  if iteration % 1000 == 0:\n",
        "    print('The Utility is',evaluation(Θ))\n",
        "    # print('The proportion is', opt_state)"
      ],
      "metadata": {
        "id": "oQ8TViggfsPL",
        "outputId": "e32f5811-1e6e-4f01-9ae4-095985da6fd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Utility is -1301.506\n",
            "The Utility is -869.2982\n",
            "The Utility is -846.71466\n",
            "The Utility is -839.00684\n",
            "The Utility is -833.38855\n",
            "The Utility is -830.0226\n",
            "The Utility is -828.1885\n",
            "The Utility is -826.8771\n",
            "The Utility is -825.7527\n",
            "The Utility is -824.7186\n",
            "The Utility is -823.7797\n",
            "The Utility is -822.95953\n",
            "The Utility is -822.26624\n",
            "The Utility is -821.70044\n",
            "The Utility is -821.2106\n",
            "The Utility is -820.8086\n",
            "The Utility is -820.4761\n",
            "The Utility is -820.17773\n",
            "The Utility is -819.92346\n",
            "The Utility is -819.6885\n",
            "The Utility is -819.4805\n",
            "The Utility is -819.30194\n",
            "The Utility is -819.0996\n",
            "The Utility is -818.935\n",
            "The Utility is -818.78064\n",
            "The Utility is -818.6075\n",
            "The Utility is -818.45886\n",
            "The Utility is -818.3211\n",
            "The Utility is -818.1902\n",
            "The Utility is -818.0672\n",
            "The Utility is -817.9671\n",
            "The Utility is -817.8436\n",
            "The Utility is -817.7755\n",
            "The Utility is -817.6581\n",
            "The Utility is -817.5817\n",
            "The Utility is -817.4724\n",
            "The Utility is -817.3819\n",
            "The Utility is -817.32\n",
            "The Utility is -817.2313\n",
            "The Utility is -817.18787\n",
            "The Utility is -817.11096\n",
            "The Utility is -817.0729\n",
            "The Utility is -817.0091\n",
            "The Utility is -816.94214\n",
            "The Utility is -816.9734\n",
            "The Utility is -816.82056\n",
            "The Utility is -816.7801\n",
            "The Utility is -816.7312\n",
            "The Utility is -816.72595\n",
            "The Utility is -816.6733\n",
            "The Utility is -816.6452\n",
            "The Utility is -816.60547\n",
            "The Utility is -816.5992\n",
            "The Utility is -816.5311\n",
            "The Utility is -816.4895\n",
            "The Utility is -816.48627\n",
            "The Utility is -816.4496\n",
            "The Utility is -816.3886\n",
            "The Utility is -816.34717\n",
            "The Utility is -816.3196\n",
            "The Utility is -816.3115\n",
            "The Utility is -816.26733\n",
            "The Utility is -816.2415\n",
            "The Utility is -816.21765\n",
            "The Utility is -816.1948\n",
            "The Utility is -816.1987\n",
            "The Utility is -816.1564\n",
            "The Utility is -816.2052\n",
            "The Utility is -816.177\n",
            "The Utility is -816.08734\n",
            "The Utility is -816.06976\n",
            "The Utility is -816.04834\n",
            "The Utility is -816.02985\n",
            "The Utility is -816.0182\n",
            "The Utility is -816.0653\n",
            "The Utility is -816.0608\n",
            "The Utility is -815.9645\n",
            "The Utility is -815.94037\n",
            "The Utility is -815.9298\n",
            "The Utility is -815.94965\n",
            "The Utility is -815.91156\n",
            "The Utility is -815.87524\n",
            "The Utility is -815.8619\n",
            "The Utility is -815.9176\n",
            "The Utility is -815.8477\n",
            "The Utility is -815.81396\n",
            "The Utility is -815.90656\n",
            "The Utility is -815.90356\n",
            "The Utility is -815.7731\n",
            "The Utility is -815.75793\n",
            "The Utility is -815.75806\n",
            "The Utility is -815.7318\n",
            "The Utility is -815.71936\n",
            "The Utility is -815.70764\n",
            "The Utility is -815.70526\n",
            "The Utility is -815.6792\n",
            "The Utility is -815.6974\n",
            "The Utility is -815.67505\n",
            "The Utility is -815.8374\n",
            "The Utility is -815.6472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppose now that your savings are fully invested in the stock market, so the evolution of wealth is now stochastic. The stock market gross return is modeled by the function below:"
      ],
      "metadata": {
        "id": "3kiR50YVel4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stock_return(rng):\n",
        "  μs = 0.06\n",
        "  σs = 0.2\n",
        "  ε = jax.random.normal(rng, ())\n",
        "  log_return = μs + σs * ε\n",
        "  return jnp.exp(log_return)"
      ],
      "metadata": {
        "id": "q29PSPOSagHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "γ = 2.\n",
        "β = 0.95\n",
        "\n",
        "\n",
        "def U(c):\n",
        "    return c**(1 - γ) / (1 - γ)\n",
        "\n",
        "\n",
        "optimizer = optax.adam\n",
        "lr = 1e-3\n",
        "T = 50\n",
        "\n",
        "\n",
        "def nnet(x):\n",
        "  X = jnp.column_stack([x])\n",
        "  X = hk.Linear(32)(X)\n",
        "  X = jnp.tanh(X)\n",
        "  X = hk.Linear(1)(X)\n",
        "  X = jnp.squeeze(X)\n",
        "  return X\n",
        "\n",
        "\n",
        "init, nnet = hk.without_apply_rng(hk.transform(nnet))\n",
        "rng = jax.random.PRNGKey(0)\n",
        "Θ = init(rng, jnp.array(1.))\n",
        "\n",
        "\n",
        "opt_state = optimizer(lr).init(Θ)\n",
        "\n",
        "\n",
        "def L(Θ):\n",
        "\n",
        "  x = 1.\n",
        "  G = 0.\n",
        "\n",
        "  state = x\n",
        "  inputs = jnp.arange(T)\n",
        "\n",
        "  def core(state, inputs):\n",
        "    t = inputs\n",
        "    xt = state\n",
        "\n",
        "    ct = jax.nn.sigmoid(nnet(Θ, xt) - 4.) * xt\n",
        "    ut = U(ct)\n",
        "    savings = xt - ct\n",
        "\n",
        "    R = stock_return(rng)\n",
        "    x_tp1 = R * savings\n",
        "\n",
        "    discounted_utility = β**t * ut\n",
        "    return x_tp1, discounted_utility\n",
        "\n",
        "  x, discounted_utility = jax.lax.scan(core, state, inputs)\n",
        "  G = discounted_utility.sum()\n",
        "  return -G\n",
        "\n",
        "\n",
        "@jax.jit\n",
        "def evaluation(Θ):\n",
        "  return -L(Θ)\n",
        "\n",
        "\n",
        "@jax.jit\n",
        "def update_gradient_descent(Θ, opt_state):\n",
        "  grad = jax.grad(L)(Θ)\n",
        "  updates, opt_state = optimizer(lr).update(grad, opt_state)\n",
        "  Θ = optax.apply_updates(Θ, updates)\n",
        "  return Θ, opt_state\n",
        "\n",
        "\n",
        "for iteration in range(100000):\n",
        "  Θ, opt_state = update_gradient_descent(Θ, opt_state)\n",
        "\n",
        "  if iteration % 1000 == 0:\n",
        "    print(evaluation(Θ))"
      ],
      "metadata": {
        "id": "4BbZ8nLxi0Hm",
        "outputId": "6ab7d614-6861-4862-bd86-a46579f373f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-918.53546\n",
            "-603.8025\n",
            "-589.3341\n",
            "-585.246\n",
            "-583.1464\n",
            "-581.8572\n",
            "-581.0594\n",
            "-580.55164\n",
            "-580.21466\n",
            "-579.953\n",
            "-579.72296\n",
            "-579.49524\n",
            "-579.26764\n",
            "-579.0636\n",
            "-578.91895\n",
            "-578.6887\n",
            "-578.5043\n",
            "-578.35565\n",
            "-578.21326\n",
            "-578.06964\n",
            "-577.96515\n",
            "-577.843\n",
            "-577.7491\n",
            "-577.7085\n",
            "-577.6126\n",
            "-577.50977\n",
            "-577.4608\n",
            "-577.3866\n",
            "-577.36285\n",
            "-577.2839\n",
            "-577.25745\n",
            "-577.24945\n",
            "-577.2052\n",
            "-577.1188\n",
            "-577.0862\n",
            "-577.0678\n",
            "-577.0211\n",
            "-576.99084\n",
            "-576.9856\n",
            "-576.9595\n",
            "-576.9342\n",
            "-576.9092\n",
            "-576.88696\n",
            "-576.865\n",
            "-576.8428\n",
            "-576.8224\n",
            "-576.8032\n",
            "-576.78516\n",
            "-576.7652\n",
            "-576.74866\n",
            "-576.73145\n",
            "-576.716\n",
            "-576.7004\n",
            "-576.68494\n",
            "-576.6708\n",
            "-576.65674\n",
            "-576.64294\n",
            "-576.63074\n",
            "-576.61896\n",
            "-576.6061\n",
            "-576.59454\n",
            "-576.5834\n",
            "-576.5721\n",
            "-576.56177\n",
            "-576.5514\n",
            "-576.54205\n",
            "-576.5316\n",
            "-576.52216\n",
            "-576.5133\n",
            "-576.5047\n",
            "-576.4957\n",
            "-576.4874\n",
            "-576.4801\n",
            "-576.4719\n",
            "-576.4646\n",
            "-576.45605\n",
            "-576.4493\n",
            "-576.4429\n",
            "-576.43616\n",
            "-576.4296\n",
            "-576.4227\n",
            "-576.4164\n",
            "-576.4103\n",
            "-576.4043\n",
            "-576.3988\n",
            "-576.39246\n",
            "-576.38696\n",
            "-576.3812\n",
            "-576.37616\n",
            "-576.37115\n",
            "-576.3656\n",
            "-576.36096\n",
            "-576.3557\n",
            "-576.3507\n",
            "-576.3457\n",
            "-576.34155\n",
            "-576.3371\n",
            "-576.33215\n",
            "-576.32764\n",
            "-576.323\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2 (20 %)\n",
        "Suppose that instead of investing the wealth entirely in the stock market, you have the option to assign a fraction $\\alpha$ of your wealth in the stock market, and the remaining is invested in a risk-free savings account that pays a 1.04 % gross return. Notice that $\\alpha$ is bounded below by 0, and bounded above by 1.\n",
        "\n",
        "Solve for the optimal consumption ($c$) and asset allocation ($\\alpha$).\n",
        "\n",
        "- Print the average sum of discounted rewards (utilities) using 1 million simulations.\n",
        "\n",
        " - Plot the average consumption-wealth ratio ($c / x)$ for each time period $t=0, 1, ..., 49$\n",
        "\n",
        " - Plot the average asset allocation in the risky asset($\\alpha)$ for each time period $t=0, 1, ..., 49$\n",
        "\n",
        "Hint: Starting from the code of the previous assignment, the modifications you have to implement are minimal. Namely:\n",
        "\n",
        "- The output of the neural network now should be a 2d vector, corresponding to the consumption-wealth ratio (c / x) and $\\alpha$, respectively\n"
      ],
      "metadata": {
        "id": "UncfcvIuYpyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "def scan_fn(carry, x):\n",
        "    new_carry = carry * 2\n",
        "    return new_carry, new_carry + x\n",
        "\n",
        "init_state = jnp.array(1.0)\n",
        "input_sequence = jnp.array([1.0, 2.0, 3.0, 4.0])\n",
        "\n",
        "final_state, result_sequence = jax.lax.scan(scan_fn, init_state, input_sequence)\n",
        "\n",
        "print(\"Final State:\", final_state)\n",
        "print(\"Result Sequence:\", result_sequence)\n"
      ],
      "metadata": {
        "id": "op3iz_aMnYRF",
        "outputId": "c8353cc5-4c47-4895-9242-4cf68227b1c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final State: 16.0\n",
            "Result Sequence: [ 3.  6. 11. 20.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import optax\n",
        "import haiku as hk\n",
        "\n",
        "\n",
        "γ = 2.\n",
        "β = 0.95\n",
        "\n",
        "\n",
        "def U(c):\n",
        "    return c**(1 - γ) / (1 - γ)\n",
        "\n",
        "\n",
        "optimizer = optax.adam\n",
        "lr = 1e-3\n",
        "T = 50\n",
        "rf_return = 1.0104\n",
        "\n",
        "\n",
        "def nnet(x):\n",
        "  X = jnp.column_stack([x])\n",
        "  X = hk.Linear(32)(X)\n",
        "  X = jnp.tanh(X)\n",
        "  X = hk.Linear(2)(X)\n",
        "  # X = jnp.squeeze(X)\n",
        "  return X\n",
        "\n",
        "\n",
        "init, nnet = hk.without_apply_rng(hk.transform(nnet))\n",
        "rng = jax.random.PRNGKey(0)\n",
        "Θ = init(rng, jnp.array(1.))\n",
        "\n",
        "\n",
        "opt_state = optimizer(lr).init(Θ)\n",
        "\n",
        "\n",
        "def L(Θ):\n",
        "\n",
        "  x = 1.\n",
        "  G = 0.\n",
        "\n",
        "  state = x\n",
        "  inputs = jnp.arange(T)\n",
        "\n",
        "  def core(state, inputs):\n",
        "    t = inputs\n",
        "    xt = state\n",
        "\n",
        "    nn_output = nnet(Θ, xt)\n",
        "    ct_x_ratio, alpha = jnp.split(nn_output, 2, axis = 1)\n",
        "    alpha = jax.nn.sigmoid(alpha)\n",
        "    ct = ct_x_ratio * xt\n",
        "    ut = U(ct)\n",
        "    savings = xt - ct\n",
        "\n",
        "    R = stock_return(rng)*alpha + rf_return*(1-alpha)\n",
        "    x_tp1 = R * savings\n",
        "\n",
        "    discounted_utility = β**t * ut\n",
        "    return x_tp1, discounted_utility\n",
        "\n",
        "  x, discounted_utility = jax.lax.scan(core, state, inputs)\n",
        "  G = discounted_utility.sum()\n",
        "  return -G\n",
        "\n",
        "\n",
        "@jax.jit\n",
        "def evaluation(Θ):\n",
        "  return -L(Θ)\n",
        "\n",
        "\n",
        "@jax.jit\n",
        "def update_gradient_descent(Θ, opt_state):\n",
        "  grad = jax.grad(L)(Θ)\n",
        "  updates, opt_state = optimizer(lr).update(grad, opt_state)\n",
        "  Θ = optax.apply_updates(Θ, updates)\n",
        "  return Θ, opt_state\n",
        "\n",
        "\n",
        "for iteration in range(100000):\n",
        "  Θ, opt_state = update_gradient_descent(Θ, opt_state)\n",
        "\n",
        "  if iteration % 1000 == 0:\n",
        "    print('The Utility is',evaluation(Θ))\n",
        "\n",
        "# Simulation\n",
        "avg_rewards = 0.0\n",
        "avg_ct_x_ratios = jnp.zeros(T)\n",
        "avg_alphas = jnp.zeros(T)\n",
        "\n",
        "for _ in range(num_simulations):\n",
        "    rng, _ = jax.random.split(rng)\n",
        "    Θ, opt_state = update_gradient_descent(Θ, opt_state)\n",
        "    avg_rewards += evaluation(Θ) / num_simulations\n",
        "\n",
        "    state = 1.\n",
        "    inputs = jnp.arange(T)\n",
        "    (_, results), _ = jax.lax.scan(core, state, inputs)\n",
        "    avg_ct_x_ratios += (results[:, 0] / inputs.size) / num_simulations\n",
        "    avg_alphas += (results[:, 1] / inputs.size) / num_simulations\n",
        "\n",
        "print(\"Average Sum of Discounted Rewards:\", avg_rewards)\n",
        "\n",
        "# Plot average consumption-wealth ratio (c / x) for each time period\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(jnp.arange(T), avg_ct_x_ratios)\n",
        "plt.xlabel(\"Time Period (t)\")\n",
        "plt.ylabel(\"Average Consumption-Wealth Ratio (c / x)\")\n",
        "plt.title(\"Average Consumption-Wealth Ratio Over Time\")\n",
        "plt.show()\n",
        "\n",
        "# Plot average asset allocation 𝛼 for each time period\n",
        "plt.plot(jnp.arange(T), avg_alphas)\n",
        "plt.xlabel(\"Time Period (t)\")\n",
        "plt.ylabel(\"Average Asset Allocation (α)\")\n",
        "plt.title(\"Average Asset Allocation Over Time\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4AiPLpYFqAOA",
        "outputId": "28200e09-42dc-40ae-de8e-e9733e846799",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-de9ad3c8bb48>\u001b[0m in \u001b[0;36m<cell line: 81>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m   \u001b[0mΘ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_gradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mΘ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-de9ad3c8bb48>\u001b[0m in \u001b[0;36mupdate_gradient_descent\u001b[0;34m(Θ, opt_state)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mupdate_gradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mΘ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m   \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mΘ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m   \u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m   \u001b[0mΘ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_updates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mΘ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 10 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-de9ad3c8bb48>\u001b[0m in \u001b[0;36mL\u001b[0;34m(Θ)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx_tp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscounted_utility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m   \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscounted_utility\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m   \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscounted_utility\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/lax/control_flow/loops.py\u001b[0m in \u001b[0;36m_check_scan_carry_type\u001b[0;34m(body_fun, in_carry, out_carry_tree, out_avals)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_aval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_aval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_avals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_avals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         if not core.typematch(in_aval, out_aval))\n\u001b[0;32m--> 317\u001b[0;31m     raise TypeError(\n\u001b[0m\u001b[1;32m    318\u001b[0m         \u001b[0;34m\"Scanned function carry input and carry output must have equal types \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;34m\"(e.g. shapes and dtypes of arrays), \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Scanned function carry input and carry output must have equal types (e.g. shapes and dtypes of arrays), but they differ:\n  * the input carry state has type float32[] but the corresponding output carry component has type float32[1,1], so the shapes do not match\n\nRevise the scanned function so that all output types (e.g. shapes and dtypes) match the corresponding input types."
          ]
        }
      ]
    }
  ]
}